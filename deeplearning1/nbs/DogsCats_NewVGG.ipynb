{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries, Set Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'allnew_vgg' from 'allnew_vgg.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils import *\n",
    "import keras.layers.convolutional as convolutional\n",
    "from keras.models import Sequential\n",
    "import allnew_vgg\n",
    "reload(allnew_vgg)\n",
    "import allnew_vgg as av\n",
    "reload(allnew_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = current_dir + '/data/kag_dogscats/' #sample/\n",
    "# data_dir = current_dir + '/data/kag_dogscats/sample/'\n",
    "results_path=data_dir + 'results/'\n",
    "train_path=data_dir + 'train/'\n",
    "valid_path=data_dir + 'valid/'\n",
    "test_path=data_dir + 'test/'\n",
    "model_path=data_dir + 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "no_of_epochs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build VGG model and load pretrained weights. Then Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.platform.ai/models/vgg16.h5\n",
      "553476096/553482496 [============================>.] - ETA: 0sDownloading data from http://www.platform.ai/models/imagenet_class_index.json\n",
      "24576/35363 [===================>..........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "vgg = av.preloaded_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg.mnn_finetuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_layers, fc_layers = vgg.layer_divider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take convolutional layers and build new model class to work off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgg = av.adjusted_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mgg.create(conv_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = mgg.mnn_batches(train_path, batch_size=batch_size, train=True, shuffle=False)\n",
    "valid = mgg.mnn_batches(valid_path, batch_size=batch_size*2, train=False, shuffle=False)\n",
    "\n",
    "train_classes = train.classes\n",
    "valid_classes = valid.classes\n",
    "train_labels = onehot(train_classes)\n",
    "valid_labels = onehot(valid_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train weights for base model built above, save them to iterate new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = mgg.model.predict_generator(generator=train, val_samples=train.nb_sample)\n",
    "valid_features = mgg.model.predict_generator(generator=valid, val_samples=valid.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_convlayer_features.bc', train_features)\n",
    "save_array(model_path+'valid_convlayer_features.bc', valid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load base weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "# valid_features = load_array(model_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model of just dense layers, using shape of trained features above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_model = mgg.dense_layer_model(fc_layers, input_shape=train_features.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "23000/23000 [==============================] - 33s - loss: 0.0633 - acc: 0.9780 - val_loss: 0.0316 - val_acc: 0.9865\n",
      "Epoch 2/8\n",
      "23000/23000 [==============================] - 34s - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0323 - val_acc: 0.9880\n",
      "Epoch 3/8\n",
      "23000/23000 [==============================] - 34s - loss: 0.0073 - acc: 0.9986 - val_loss: 0.0795 - val_acc: 0.9855\n",
      "Epoch 4/8\n",
      "23000/23000 [==============================] - 34s - loss: 0.0032 - acc: 0.9997 - val_loss: 0.0848 - val_acc: 0.9870\n",
      "Epoch 5/8\n",
      "23000/23000 [==============================] - 34s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1193 - val_acc: 0.9845\n",
      "Epoch 6/8\n",
      "23000/23000 [==============================] - 34s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1005 - val_acc: 0.9880\n",
      "Epoch 7/8\n",
      "23000/23000 [==============================] - 33s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1052 - val_acc: 0.9865\n",
      "Epoch 8/8\n",
      "23000/23000 [==============================] - 33s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.1055 - val_acc: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ea413d350>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(x=train_features, y=train_labels, nb_epoch=8, batch_size=64, validation_data=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(results_path+'dogcats_clean.h5')\n",
    "# fc_model.load_weights(results_path+'dogcats_clean.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Weights from New Model with Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in fc_layers: \n",
    "    mgg.model.add(layer)\n",
    "\n",
    "for l1,l2 in zip(fc_model.layers, mgg.model.layers[len(conv_layers):]):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Batches and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size*2, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = mgg.model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "\n",
    "save_array(results_path + 'test_predictions.dat', predictions)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting submission correctly, including \"clipped\" max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = mgg.submission_formatter(filenames, predictions, 1, .055, .945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Predictions CSV and Generating a Click-able Link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(results_path+'clean_model_submission.csv', subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%kg` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/results\n"
     ]
    }
   ],
   "source": [
    "# if filelink is not working, use commands below in command line\n",
    "# %kg submit results/clean_model_submission.csv -m \"Adding dropout and augmentation to VGG16.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='clean_model_submission.csv' target='_blank'>clean_model_submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/data/kag_dogscats/results/clean_model_submission.csv"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink(results_path+'clean_model_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:fastai_py27]",
   "language": "python",
   "name": "conda-env-fastai_py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
